# -*- coding: utf-8 -*-
"""Stroke Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cEH5oEMNtSHkJP-eKSmiY0KvkNvo832f
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.impute import KNNImputer

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
import pickle

from google.colab import files
files.upload()

!ls -lha kaggle.json
!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d fedesoriano/stroke-prediction-dataset

!unzip stroke-prediction-dataset

stroke = pd.read_csv('healthcare-dataset-stroke-data.csv')
stroke

stroke.shape

stroke.info()

stroke.describe()

stroke.isna().sum()

stroke.columns

imputer = KNNImputer(n_neighbors=5)
stroke['bmi'] = imputer.fit_transform(stroke[['bmi']])

stroke.isna().sum()

fig, axes = plt.subplots(figsize=(8,4))
stroke['stroke'].value_counts(normalize=True).plot.bar(width=0.2, color=('orange','green'))

plt.tight_layout()
plt.show()

"""Non Categorical Features



"""

cols = stroke[['age','hypertension','heart_disease','avg_glucose_level','bmi']]
cols.head()

plt.figure(figsize = (20,30), facecolor= 'white')
plotnumber = 1


for column in cols:
  if plotnumber <= 15:
    ax = plt.subplot(5,3,plotnumber)
    sns.distplot(cols[column])
    plt.xlabel(column, fontsize=20)

  plotnumber +=1
plt.tight_layout()

plt.figure(figsize=(20,30), facecolor ='white')
plotnumber =1 

for column in cols:
  if plotnumber <=15:
    ax = plt.subplot(5,3,plotnumber)
    sns.boxplot(cols[column])
    plt.xlabel(column, fontsize=20)

  plotnumber+=1
plt.tight_layout()

sns.countplot(stroke['gender'])

sns.countplot(stroke['ever_married'])

sns.countplot(stroke['work_type'])

sns.countplot(stroke['Residence_type'])

sns.countplot(stroke['smoking_status'])

"""Categorical Features"""

categorical_features = ['gender','ever_married','work_type','Residence_type','smoking_status']

fig, axes = plt.subplots(2, 3, figsize=(20,10))
axes = [ax for axes_row in axes for ax in axes_row]
target = 'stroke'

for i,c in enumerate(categorical_features):
  sns.barplot(stroke[c],stroke[target], ax=axes[i])
  axes[i].set_ylabel('stroke',fontsize =14)
  axes[i].set_xlabel(c,fontsize =14)

plt.tight_layout()
plt.show()

stroke.smoking_status.unique()

gender = pd.get_dummies(stroke[['gender']], drop_first=True)
gender.head()

married = pd.get_dummies(stroke[['ever_married']], drop_first=True)
married.head()

work = pd.get_dummies(stroke[['work_type']], drop_first=True)
work.head()

residence = pd.get_dummies(stroke[['Residence_type']], drop_first=True)
residence.head()

smoke = pd.get_dummies(stroke[['smoking_status']], drop_first=True)
smoke.head()

data = pd.concat([stroke,gender,married,work,residence,smoke], axis=1)
data.head()

data = data.drop(columns=categorical_features, axis=1)
data.head()

data = data.drop(columns="id", axis=1)
data.head()

corr = data.corr()['stroke'].sort_values(ascending=False).to_frame()
plt.figure(figsize=(2,8))
sns.heatmap(corr, cmap='Reds', cbar=False, annot=True)
plt.show()

X = data.drop('stroke',axis=1)
X.head()

Y = data[['stroke']]
Y.head()

scaler = StandardScaler()
X = scaler.fit_transform(X)

X

x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=36)

x_train

decision = DecisionTreeClassifier(random_state=10)
decision.fit(x_train, y_train)

decision.score(x_test, y_test)

RF = RandomForestClassifier(max_depth = 13, n_estimators = 10, max_features='sqrt')
RF.fit(x_train,y_train)

RF.score(x_test,y_test)

svc = SVC()
svc.fit(x_train,y_train)

svc.score(x_test,y_test)

knn = KNeighborsClassifier()
knn.fit(x_train,y_train)

knn.score(x_test,y_test)

param_grid = {'C' : [0.1,1,10,100,100],
              'gamma' : [1,0.1,0.01,0.001,0.0001],
              'kernel' : ['rbf']}

grid = GridSearchCV(SVC(),param_grid, refit= True, verbose=3)
grid.fit(x_train,y_train)

grid.best_params_

model = SVC(C= 0.1, gamma = 1, kernel='rbf')
model.fit(x_train,y_train)

model.score(x_test,y_test)

pred = model.predict(x_test)

print(classification_report(y_test,pred))

with open('model_pickle','wb') as file:
  pickle.dump(model,file)